# AI Secretary - アーキテクチャ設計

## 概要

AI Secretaryは、Ollamaを活用したローカルAI秘書システムです。
すべての処理がローカル環境で完結し、プライバシーを重視した設計となっています。

## システム構成

### コアコンポーネント

1. **AISecretary (secretary.py)**
   - メインの秘書クラス
   - ユーザーとの対話を管理
   - 会話履歴の保持
   - タスク実行のオーケストレーション

2. **OllamaClient (ollama_client.py)**
   - Ollama APIとの通信を担当
   - JSON形式レスポンスを基本とする
   - chat()とgenerate()の2つの主要メソッド
   - ストリーミング対応

3. **Config (config.py)**
   - 設定管理
   - 環境変数からの設定読み込み
   - デフォルト値の提供
   - Ollama接続設定（ホスト、モデル名等）

4. **Logger (logger.py)**
   - ロギング設定
   - ファイルとコンソールへの出力
   - レベル別のログ管理

## データフロー

```
ユーザー入力
    ↓
AISecretary
    ↓
OllamaClient
    ↓
Ollama (localhost:11434)
    ↓
JSON形式レスポンス
    ↓
OllamaClient (パース)
    ↓
AISecretary (履歴管理)
    ↓
ユーザーへの出力
```

## JSON形式レスポンスの設計

### 基本方針

- すべてのOllama APIリクエストはデフォルトで`format="json"`を指定
- レスポンスは辞書型オブジェクトとして返される
- 必要に応じて`return_json=False`でテキスト形式も取得可能

### メリット

1. **構造化データ**: 複雑な情報を構造化して取得可能
2. **型安全**: Pythonの辞書として扱えるため型チェックが容易
3. **パース不要**: 手動でのパースが不要
4. **拡張性**: スキーマ定義によって柔軟な応答形式を実現

## 今後の拡張予定

- タスク管理機能（JSONスキーマベース）
- スケジュール管理
- リマインダー機能
- 外部サービス連携（カレンダー、メールなど）
- 複数モデルの動的切り替え
- 会話履歴の永続化

## セキュリティ考慮事項

- すべての処理がローカル環境で完結
- 外部APIへのデータ送信なし
- .envファイルは.gitignoreに追加
- ログファイルに機密情報を記録しない
- Ollama通信はローカルホストのみ（デフォルト）

## テスト戦略

- pytest による単体テスト
- 実際のOllama APIを使用した統合テスト
- JSON形式レスポンスの検証
- エラーハンドリングのテスト
